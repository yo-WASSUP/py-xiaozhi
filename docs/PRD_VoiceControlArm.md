# 语音交互控制机械臂系统 - 产品需求文档 (PRD)

> 版本: v1.0 MVP
> 日期: 2026-02-05

---

## 1. 产品概述

### 1.1 产品定位
基于语音交互的ROS2机械臂控制系统，面向工业生产环境，提供自然语言控制、实时状态反馈、安全急停等核心能力。系统**完全部署于机械臂端侧**（边缘计算设备：Jetson/Orin NX），通过可配置的 API 接口调用云端服务（ASR/TTS/LLM），支持离线降级运行。

### 1.2 核心价值
- **解放双手**: 操作人员无需触碰控制面板，语音即可控制机械臂
- **降低门槛**: 自然语言交互，无需记忆复杂指令
- **安全优先**: 毫秒级语音急停响应，多重安全机制保障
- **灵活部署**: 混合架构支持离线基础命令+在线智能对话

### 1.3 目标用户
- 工业产线操作人员
- 一般用户

---

## 2. 系统架构

### 2.1 整体架构图

```
┌──────────────────────────────────────────────────────────────────────┐
│                            语音控制模块                                │
│              部署于机械臂端侧 (Jetson Orin NX / 边缘设备)             │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌─────────────┐    ┌──────────────┐    ┌─────────────────────┐    │
│  │  音频输入    │───▶│ VAD（语音活动检测） │───▶│   本地 ASR (语音识别)   │    │
│  │ (麦克风) │    │ 唤醒词检测   │    │   Sherpa/FunASR     │    │
│  └─────────────┘    └──────────────┘    └──────────┬──────────┘    │
│                                                     │               │
│  ┌──────────────────────────────────────────┐      │               │
│  │    急停 KWS (关键词检测 - 最高优先级)     │◀─────┤               │
│  │  "停"/"急停" → 立即输出急停指令          │      │               │
│  └──────────────────┬───────────────────────┘      │               │
│                     │ (<200ms)                      │               │
│                     │                              │               │
│                     ▼                              ▼               │
│  ┌────────────────────────────────────────────────────────────┐    │
│  │                    命令解析模块                             │    │
│  │  ┌──────────────┐      ┌────────────────────────────┐      │    │
│  │  │  本地规则匹配 │ ───▶ │  未匹配 → API调用 │      │    │
│  │  │  预设点位/    │      │  • DeepSeek / Qwen         │      │    │
│  │  │  基础命令     │      │          │      │    │
│  │  └──────────────┘      │  • 自建 LLM 服务 │      │    │
│  │                        └────────────────────────────┘      │    │
│  └────────────────────────────────┬───────────────────────────┘    │
│                                   │                                │
│                                   ▼                                │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │              结构化指令输出 (JSON)                           │   │
│  │  {"action": "move_to_point", "params": {"point": "A"}}      │   │
│  └────────────────────────────────┬────────────────────────────┘   │
│                                   │                                │
│  ┌─────────────┐    ┌──────────────┴───────────┐                   │
│  │  音频输出    │◀───│    TTS（文本转语音）模块   │                   │
│  │  (扬声器)   │    │ • 阿里云 / edge-tts      │                   │
│  └─────────────┘    └──────────────────────────┘                   │
│                                                                    │
│  ┌──────────────────────────────────────────────────────────────┐ │
│  │            Web 本地控制面板 (FastAPI + Vue3)                  │ │
│  │  • 命令日志查看 (识别结果/输出指令)                           │ │
│  │  • 配置管理 (点位映射/API密钥)                                │ │
│  │  • 测试工具 (手动输入文本 → 输出指令)                         │ │
│  └──────────────────────────────────────────────────────────────┘ │
│                                                                    │
└────────────────────────────────────┬───────────────────────────────┘
                                     │
                                     │ 结构化指令输出 (JSON/消息队列/API)
                                     │
                          ═══════════▼═══════════════

                ┌─────────────────────────────────────────┐
                │   机械臂控制系统 (公司已有)   │
                ├─────────────────────────────────────────┤
                │  • 接收 JSON 格式的控制指令              │
                │  • ROS2 / 专有协议 / 其他方式           │
                │  • 执行具体的运动控制                   │
                └─────────────────────────────────────────┘

                          ═══════════▲═══════════════
                          可选: 状态反馈 (用于 TTS 播报)
                          ═══════════║═══════════════
                                     ║
                ┌────────────────────╝────────────────────┐
                │      云端 API 服务 (可配置)              │
                ├──────────────────────────────────────────┤
                │ • ASR: 阿里云流式/Whisper                │
                │ • LLM: DeepSeek/Qwen/GLM                 │
                │ • TTS: 阿里云/edge-tts                   │
                └──────────────────────────────────────────┘
```

### 2.2 技术栈选型

| 层级 | 技术选型 | 说明 |
|-----|---------|------|
| **硬件平台** | Jetson Orin NX | GPU加速，支持本地模型推理 |
| **操作系统** | Ubuntu 22.04 | 稳定性好，长期支持 |
| **音频处理** | py-xiaozhi 核心模块 | 复用 VAD/唤醒词/音频编解码 |
| **唤醒词** | Sherpa-ONNX (本地) | 离线唤醒，<300ms 响应 |
| **急停 KWS** | Sherpa-ONNX Keywords | 本地关键词检测，<200ms 极速响应 |
| **ASR (可配置)** | **本地**: Sherpa-ONNX/FunASR<br>**API**: 阿里云流式ASR | 支持离线降级 + 云端高精度 |
| **NLU (可配置)** | **本地**: 规则匹配<br>**API**: DeepSeek/Qwen/GLM/Doubao | 本地规则匹配 + 云端复杂意图理解 |
| **TTS (可配置)** | **本地**: edge-tts<br>**API**: 阿里云TTS | 支持多种语音合成方案 |
| **指令输出** | 暂未定 | 灵活适配下游系统 |
| **Web 框架** | FastAPI + Vue3 | 轻量级本地控制面板 |
| **配置管理** | YAML + 环境变量 | API 密钥加密存储 |

---

## 3. 功能需求

### 3.1 MVP核心功能

#### 3.1.1 语音唤醒与监听
| 功能点 | 描述 | 验收标准 |
|-------|------|---------|
| 唤醒词激活 | 支持自定义唤醒词（默认"贾维斯"） | 3米内唤醒成功率 > 95% |
| 按键激活 | 物理按键/快捷键触发监听 | 按下即响应 |
| VAD检测 | 自动检测语音结束 | 语音结束后500ms内停止录音 |
| 噪声抑制 | 工业环境噪声过滤 | 75dB环境下正常工作 |

#### 3.1.2 自然语言对话
| 功能点 | 描述 | 实现方式 |
|-------|------|---------|
| 通用对话能力 | 像通用聊天机器人一样进行自然对话 | LLM API (DeepSeek/Qwen/GLM/Doubao) |
| 个性化特征 | 具有独特的性格设定和语言风格 | System Prompt 配置 |
| 长期记忆 | 记住用户偏好、历史对话和设备状态 | 会话历史管理 + 向量数据库 |
| 机械臂控制意图识别 | 从对话中识别控制指令并执行 | LLM 函数调用 (Function Calling) |

**对话场景示例**:
| 场景 | 对话示例 | 说明 |
|-----|---------|------|
| 日常对话 | 用户："今天天气怎么样？"<br>机器人："今天阳光不错，适合工作呢！" | 通用聊天能力 |
| 任务对话 | 用户："帮我把工件移到A点"<br>机器人："好的，正在移动到A点" → 输出控制指令 | 识别任务意图并执行 |
| 记忆能力 | 用户："上次那个焊接轨迹再来一遍"<br>机器人："好的，执行焊接轨迹1" | 记住历史操作 |
| 个性化回复 | 用户："你累不累？"<br>机器人："我可是钢铁之躯，24小时待命！" | 有性格的回复 |

#### 3.1.3 紧急语音控制 (最高优先级)
| 命令 | 响应时间 | 处理方式 |
|-----|---------|---------|
| "停"/"停止"/"急停" | < 200ms | 立即中断当前动作，触发急停 |
| "暂停" | < 300ms | 暂停当前轨迹，可恢复 |
| "继续" | < 300ms | 恢复暂停的动作 |

#### 3.1.4 状态查询与反馈
| 查询类型 | 示例 | 反馈方式 |
|---------|------|---------|
| 位置查询 | "当前位置"、"在哪里" | 语音播报坐标/点位名 |
| 状态查询 | "什么状态"、"在干什么" | 播报当前运动状态 |

#### 3.1.5 示教记录（后续可扩展）
| 功能 | 命令示例 | 说明 |
|-----|---------|------|
| 记录点位 | "记住这个位置叫B点" | 保存当前关节角度 |
| 开始录制 | "开始记录轨迹" | 录制后续运动 |
| 停止录制 | "停止录制，保存为轨迹1" | 保存轨迹 |

### 3.2 安全机制

#### 3.2.1 语音优先级
```
优先级 0 (最高): 急停命令 - 本地KWS直接触发，绕过所有处理
优先级 1: 暂停/继续 - 本地快速处理
优先级 2: 运动命令 - 正常ASR+NLU流程
```

#### 3.2.2 语音认证
- 声纹识别功能
- 支持配置授权操作员列表
- 未授权人员只能执行查询操作

#### 3.2.3 操作日志
- 记录所有语音命令和识别结果
- 记录命令执行状态和结果
- 支持日志查询和导出

### 3.3 Web控制面板

#### 3.3.1 状态监控页
- 语音模块状态（监听中/处理中/空闲）
- 系统资源监控（CPU/GPU/内存）
- 输出通道状态（HTTP 连接/消息队列状态）

#### 3.3.2 命令日志页
- 实时命令流显示（输出的 JSON 指令）
- 识别结果和置信度
- 输出状态（成功/失败/重试）
- 筛选和搜索功能
- 导出日志功能

#### 3.3.3 配置管理页
- 唤醒词配置
- 预设点位映射表
- 轨迹名称映射表
- API 密钥管理
- 输出方式配置（HTTP 端点/消息队列地址）

#### 3.3.4 测试工具页
- 手动输入文本 → 查看输出 JSON
- 模拟语音识别结果
- 测试指令输出通道

### 3.4 自然语言对话 (Agent 模块)

系统的核心是一个具有通用对话能力的 AI Agent，在此基础上扩展机械臂控制能力。

#### 3.4.1 通用对话能力

**个性化设定**:
- 支持自定义 Agent 性格（专业/幽默/严肃/友好）
- 可配置语言风格和回复模板
- 配置文件：`config/agent_personality.yaml`

**记忆系统**:
| 记忆类型 | 存储内容 | 实现方式 |
|---------|---------|---------|
| 短期记忆 | 当前会话的上下文（最近10轮对话） | LLM 上下文窗口 |
| 工作记忆 | 当前任务状态、设备状态、未完成指令 | 内存状态管理 |

**对话模式**:
- **闲聊模式**: 纯对话交流，无控制意图
- **任务模式**: 识别控制意图并执行
- **混合模式**: 边聊天边执行任务

#### 3.4.2 机械臂控制意图识别

通过 LLM 的 **Function Calling** 能力实现：

**工作流程**:
```
用户语音 → ASR识别 → LLM分析意图
                         ↓
           ┌─────────────┴─────────────┐
           │                           │
    识别为控制指令              识别为普通对话
           │                           │
           ▼                           ▼
    调用控制函数              生成对话回复
    (move_to, grip, etc.)     (闲聊/答疑)
           │                           │
           ▼                           ▼
    输出JSON指令              TTS语音播报
```

**LLM Function Calling 定义**:

系统会向 LLM 提供以下可调用函数：

| 函数名 | 说明 | 参数示例 |
|-------|------|---------|
| `move_to_point` | 移动到预设点位 | `{"point": "A", "speed": 0.5}` |
| `gripper_control` | 控制夹爪 | `{"action": "grip", "force": 50}` |
| `relative_move` | 相对移动 | `{"direction": "left", "distance": 0.1}` |
| `query_status` | 查询状态 | `{"query_type": "position"}` |
| `emergency_stop` | 紧急停止 | `{}` |

#### 3.4.3 复杂场景处理

**上下文理解**:
| 场景 | 用户指令 | LLM 处理 |
|-----|---------|---------|
| 模糊指令 | "去那个抓东西的位置" | 推断为"抓取点" → `move_to_point("抓取点")` |
| 省略参数 | "慢慢移动到B点" | 推断speed=0.2 → `move_to_point("B", speed=0.2)` |

**多步骤任务**:
用户："先去A点，然后抓取，最后回到原点"

LLM 生成任务序列：
```json
[
  {"action": "move_to_point", "params": {"point": "A"}},
  {"action": "gripper_control", "params": {"action": "grip"}},
  {"action": "move_to_point", "params": {"point": "HOME"}}
]
```

**对话式确认**:
```
用户: "帮我把工件移到那个危险区域"
Agent: "你是说C点吗？那里是高温区，确定要移动吗？"
用户: "确定"
Agent: "收到，正在移动" → 输出控制指令
```

#### 3.4.4 实现方式

**本地规则 + LLM API 混合架构**:
- 简单命令（如"停止"、"移动到A点"）优先使用本地规则匹配（低延迟）
- 复杂对话和意图理解调用 LLM API
- 离线时仅支持预设命令词表

**LLM 提供商支持**:
- DeepSeek API
- 通义千问 (Qwen)
**配置文件**: `config/api_providers.yaml`

---

## 4. 非功能需求

### 4.1 性能要求

| 指标 | 要求 | 测量方式 |
|-----|------|---------|
| 唤醒响应 | < 300ms | 唤醒词结束到第一次语音响应 |
| 急停响应 | < 200ms | 命令发出到电机停止 |
| 普通命令响应 | < 500ms | 命令结束到动作开始 |
| 语音识别准确率 | > 95% | 标准工业环境 |
| 系统可用性 | > 99.5% | 24小时运行 |

### 4.2 可靠性要求

- 网络断开时基础命令仍可执行
- 服务崩溃自动重启
- 音频设备异常自动恢复
- 指令输出失败时重试机制（可配置）
- 心跳检测确保下游系统在线

### 4.3 安全要求

- 所有通信加密 (TLS/DDS Security)
- 敏感配置加密存储
- 操作日志不可篡改
- 符合工业安全标准 (ISO 10218)
---

## 5. 技术设计要点

### 5.1 复用py-xiaozhi模块

| 模块 | 复用程度 | 修改说明 |
|-----|---------|---------|
| 音频编解码 | **完全复用** | `audio_codecs/*` |
| VAD检测 | **完全复用** | `audio_processing/vad_detector.py` |
| 唤醒词检测 | **完全复用** | `audio_processing/wake_word_detect.py` |
| 配置管理 | **完全复用** | `utils/config_manager.py` |
| 音频设备管理 | **完全复用** | `audio/audio_input.py` |
| IoT 框架 | **参考设计** | 改造为 ROS2 设备抽象层 |
| WebSocket协议 | **不复用** | 改用直接 API 调用 (HTTP/REST) |

### 5.2 模块设计

```
voice_arm_control/
├── main.py                      # 入口程序
├── src/
│   ├── application.py           # 应用核心（参考 py-xiaozhi 设计）
│   │
│   ├── audio/                   # 音频处理（复用 py-xiaozhi）
│   │   ├── audio_input.py       # 音频采集
│   │   ├── audio_codec.py       # 编解码
│   │   ├── vad_detector.py      # VAD 检测
│   │   └── wake_word_detect.py  # 唤醒词检测
│   │
│   ├── asr/                     # 语音识别（多引擎支持）
│   │   ├── asr_base.py          # ASR 抽象基类
│   │   ├── local_asr.py         # 本地 ASR (Sherpa/FunASR)
│   │   ├── api_asr.py           # API ASR (流式阿里云)
│   │   └── emergency_kws.py     # 急停关键词检测（最高优先级）
│   │
│   ├── nlu/                     # 自然语言理解
│   │   ├── rule_parser.py       # 本地规则引擎 (YAML 配置)
│   │   ├── intent_classifier.py # 意图分类器
│   │   ├── command_generator.py # 生成标准 JSON 指令
│   │   └── llm_client.py        # LLM API 客户端（可配置多提供商）
│   │       ├── openai_adapter.py
│   │       └── custom_adapter.py
│   │
│   ├── tts/                     # 语音合成（多引擎支持）
│   │   ├── tts_base.py          # TTS 抽象基类
│   │   ├── local_tts.py         # 本地 TTS (edge-tts/Piper)
│   │   └── api_tts.py           # API TTS (流式阿里云)
│   │
│   ├── output/                  # 指令输出模块 (新增)
│   │   ├── publisher_base.py    # 输出抽象基类
│   │   ├── http_publisher.py    # HTTP API 输出
│   │   ├── mq_publisher.py      # 消息队列输出
│   │   ├── ws_publisher.py      # WebSocket 输出
│   │   └── file_publisher.py    # 文件输出
│   │
│   ├── safety/                  # 安全模块
│   │   ├── emergency_handler.py # 急停处理（最高优先级）
│   │   ├── command_validator.py # 命令安全验证
│   │   └── voice_auth.py        # 语音认证（可选）
│   │
│   ├── web/                     # Web 本地控制面板
│   │   ├── api.py               # FastAPI 后端
│   │   ├── websocket.py         # 实时日志推送
│   │   └── static/              # Vue3 前端资源
│   │       ├── index.html
│   │       └── assets/
│   │
│   └── utils/                   # 工具类
│       ├── config_manager.py    # 配置管理
│       ├── logger.py            # 日志记录
│       └── api_key_manager.py   # API 密钥加密存储
│
├── config/
│   ├── config.yaml              # 主配置文件
│   ├── api_providers.yaml       # API 提供商配置
│   ├── output.yaml              # 指令输出配置
│   ├── commands.yaml            # 命令映射规则
│   ├── points.yaml              # 预设点位映射
│   └── trajectories.yaml        # 预录轨迹映射
│
├── models/                      # 本地模型文件
│   ├── wake_word/               # 唤醒词模型
│   ├── asr/                     # 本地 ASR 模型
│   └── tts/                     # 本地 TTS 模型
│
└── logs/                        # 日志目录
    ├── commands/                # 输出的 JSON 指令日志
    └── system/                  # 系统运行日志
```

### 5.3 对话与控制处理流程

```
                          语音输入 (麦克风阵列)
                                  │
                                  ▼
                    ┌──────────────────────────┐
                    │  VAD + 唤醒词检测 (本地)  │
                    │   "贾维斯" (Sherpa-ONNX) │
                    └────────────┬─────────────┘
                                 │ 激活监听
                                 ▼
        ┌────────────────────────────────────────────────┐
        │           并行处理: 急停 KWS 检测               │
        │  (独立线程, 最高优先级, <200ms 响应)            │
        └────────────┬───────────────────────────────────┘
                     │
         ┌───────────┴───────────┐
         │                       │
    检测到急停词              无急停词
    "停"/"急停"                  │
         │                       │
         ▼                       ▼
┌────────────────────┐   ┌───────────────────────────┐
│ 立即输出急停指令    │   │   ASR 语音识别 (可配置)    │
│ emergency_stop     │   │ • 本地: Sherpa/FunASR     │
│ (<200ms)           │   │ • API: 阿里云流式ASR      │
└────────────────────┘   └─────────────┬─────────────┘
         │                             │ 识别文本
         │                             ▼
         │          ┌───────────────────────────────────────────┐
         │          │         AI 对话代理 (LLM Agent)            │
         │          │  • 加载对话历史和上下文                   │
         │          │  • 加载个性化设定 (System Prompt)         │
         │          │  • 记忆管理 (短期记忆 + 工作记忆)         │
         │          └──────────────┬────────────────────────────┘
         │                         │ 意图分析
         │                         ▼
         │          ┌──────────────────────────────────────────┐
         │          │      LLM 意图识别与决策                   │
         │          │  (DeepSeek/Qwen/GLM with Function Calling)│
         │          └──────────┬───────────────────────────────┘
         │                     │
         │      ┌──────────────┼──────────────┐
         │      │              │              │
         │   纯对话       控制意图        离线模式
         │   闲聊        (Function Call)      │
         │      │              │              │
         │      ▼              ▼              ▼
         │  ┌─────────┐  ┌──────────────┐ ┌─────────────┐
         │  │ 生成回复 │  │ 调用控制函数  │ │ 本地规则匹配 │
         │  │ "今天..."│  │ move_to_point│ │ (离线降级)   │
         │  └────┬────┘  │ gripper...   │ └──────┬──────┘
         │       │       └──────┬───────┘        │
         │       │              │                │
         │       │              ▼                │
         │       │     ┌─────────────────────┐  │
         │       │     │   命令安全验证       │  │
         │       │     │ • 危险动作确认      │  │
         │       │     │ • 速度/范围检查     │  │
         │       │     │ • 语音认证(可选)    │  │
         │       │     └──────────┬──────────┘  │
         │       │                │ 通过验证    │
         │       │                ▼             │
         └───────┼───────────────▶┌─────────────┴──────────┐
                 │                │  生成标准 JSON 指令      │
                 │                │  command_generator.py   │
                 │                └──────────┬──────────────┘
                 │                           │
                 │                           ▼
                 │                ┌─────────────────────────┐
                 │                │  输出到下游系统          │
                 │                │ • HTTP POST             │
                 │                │ • 消息队列              │
                 │                │ • WebSocket             │
                 │                └──────────┬──────────────┘
                 │                           │
                 ▼                           ▼
         ┌──────────────────┐   ┌──────────────────────┐
         │  TTS 语音反馈     │   │  TTS 语音反馈         │
         │ "好的，正在移动   │   │ "今天阳光不错，      │
         │  到A点"          │   │  适合工作呢！"       │
         └────────┬─────────┘   └──────────┬───────────┘
                  │                        │
                  └───────────┬────────────┘
                              │
                              ▼
                       扬声器输出播报
                              │
                              ▼
               ┌──────────────────────────────────┐
               │   更新对话上下文和记忆系统        │
               │ • 保存对话历史                   │
               │ • 更新工作记忆（设备状态/任务）   │
               └──────────────────────────────────┘

                              │
                              ▼
               ┌─────────────────────────────────────┐
               │  下游机械臂控制系统 (不需要你管)     │
               │  接收 JSON → 执行具体运动控制       │
               └─────────────────────────────────────┘

【关键路径延迟】
- 急停命令: 语音输入 → 电机停止 < 200ms
- 纯对话: 语音输入 → TTS 播报 < 2s (取决于 LLM API)
- 控制命令 (LLM): 语音输入 → 动作开始 < 2s (取决于网络)
- 控制命令 (离线): 语音输入 → 动作开始 < 500ms
```

### 5.4 控制指令输出接口设计

**注**: 语音模块只负责输出结构化的 JSON 指令，具体的机械臂控制由下游系统处理。

#### 5.4.1 标准指令格式 (JSON Schema)

所有语音命令最终转换为统一的 JSON 格式：

```json
{
  "command_id": "uuid-string",        // 唯一标识，用于追踪
  "timestamp": 1706000000.123,        // Unix 时间戳（毫秒）
  "priority": 0,                      // 优先级: 0=急停, 1=暂停, 2=运动, 3=查询
  "action": "move_to_point",          // 动作类型
  "params": {                         // 参数（根据 action 不同而变化）
    "point": "A",
    "speed": 0.5
  },
  "source": {                         // 来源信息
    "type": "voice",                  // voice / web / test
    "raw_text": "慢慢移动到A点",       // 原始语音文本
    "confidence": 0.95                // ASR 置信度
  }
}
```

实现文件: `src/nlu/command_generator.py`
---

## 6. MVP里程碑

### Phase 1: 核心对话与控制 (MVP核心)
- [ ] 音频采集和唤醒词检测
- [ ] 本地ASR语音识别 (Sherpa-ONNX/FunASR)
- [ ] **LLM API 集成**（DeepSeek/Qwen 等多提供商支持）
- [ ] **通用对话能力**（性格设定、短期记忆、闲聊模式）
- [ ] **机械臂控制意图识别**（Function Calling 实现）
- [ ] 基础命令规则解析（离线降级方案）
- [ ] JSON 指令生成和输出接口
- [ ] 语音急停功能 (KWS 独立检测)
- [ ] TTS状态反馈
- [ ] HTTP/文件输出方式实现

### Phase 2: 安全与监控
- [ ] 命令确认机制
- [ ] 操作日志记录
- [ ] Web状态监控页面
- [ ] 基础配置管理
- [ ] 声纹识别（可选）

### Phase 3: 高级对话与扩展功能
- [ ] **长期记忆系统**（向量数据库 + 历史对话存储）
- [ ] **多轮上下文管理**（复杂任务规划）
- [ ] 示教记录功能（语音保存点位/轨迹）
- [ ] API 密钥管理与加密存储
- [ ] 对话式确认机制（危险操作二次确认）

---

## 7. 风险与应对

| 风险 | 影响 | 应对措施 |
|-----|------|---------|
| 工业噪声影响识别率 | 高 | 采用麦克风阵列+波束成形 |
| 网络不稳定影响云端NLU | 中 | 混合架构，离线保底 |
| 急停响应延迟 | 高 | 独立KWS通道，最高优先级 |
| ROS2版本兼容性 | 中 | 抽象接口层，适配多版本 |

---

### 8.5 参考资料

- [py-xiaozhi 项目](https://github.com/huangjunsen0406/py-xiaozhi)
- [Sherpa-ONNX 语音识别](https://github.com/k2-fsa/sherpa-onnx)
- [FunASR 语音识别](https://github.com/alibaba-damo-academy/FunASR)
- [阿里云语音服务](https://help.aliyun.com/zh/isi/)
- [DeepSeek API](https://platform.deepseek.com/)

---
